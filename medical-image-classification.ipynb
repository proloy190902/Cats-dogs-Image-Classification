{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, Convolution2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image  import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-13T08:32:57.075929Z","iopub.execute_input":"2022-12-13T08:32:57.077179Z","iopub.status.idle":"2022-12-13T08:32:57.085472Z","shell.execute_reply.started":"2022-12-13T08:32:57.077123Z","shell.execute_reply":"2022-12-13T08:32:57.084567Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\n# Conv 01 Layer\nmodel.add(Convolution2D(96, 11,padding = \"valid\",strides =(4, 4),input_shape = (224, 224, 3),activation = \"relu\"))\n\nmodel.add(MaxPooling2D(pool_size = (2, 2),strides = (2, 2),padding=\"valid\"))\nmodel.add(BatchNormalization())\n\n\n\n# Conv 02 Layer\nmodel.add(Convolution2D(256, 5,padding = \"valid\",strides =(1, 1),activation = \"relu\"))\n\nmodel.add(MaxPooling2D(pool_size = (2, 2),strides = (2, 2),padding=\"valid\"))\nmodel.add(BatchNormalization())\n\n\n# Conv 03 Layer\nmodel.add(Convolution2D(384, 3,padding = \"valid\",strides =(1, 1),activation = \"relu\"))\nmodel.add(BatchNormalization())\n\n\n# Conv 04 Layer\nmodel.add(Convolution2D(384, 3,padding = \"valid\",strides =(1, 1),activation = \"relu\"))\nmodel.add(BatchNormalization())\n\n\n\n# Conv 05 Layer\nmodel.add(Convolution2D(256, 3,padding = \"valid\",strides =(1, 1),activation = \"relu\"))\n\nmodel.add(MaxPooling2D(pool_size = (3, 3),strides = (2, 2),padding=\"valid\"))\nmodel.add(BatchNormalization())\n\n\n# Flatten Layer\nmodel.add(Flatten())\n\n\n# Dense 01\nmodel.add(Dense(4096, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\n\n# Dense 02\nmodel.add(Dense(4096, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\n\n# Dense 03\nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\n\n# Final Layer\nmodel.add(Dense(3, activation=\"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:32:57.109025Z","iopub.execute_input":"2022-12-13T08:32:57.110088Z","iopub.status.idle":"2022-12-13T08:32:57.507313Z","shell.execute_reply.started":"2022-12-13T08:32:57.110047Z","shell.execute_reply":"2022-12-13T08:32:57.506410Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:32:57.509102Z","iopub.execute_input":"2022-12-13T08:32:57.509762Z","iopub.status.idle":"2022-12-13T08:32:57.519686Z","shell.execute_reply.started":"2022-12-13T08:32:57.509723Z","shell.execute_reply":"2022-12-13T08:32:57.518350Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 54, 54, 96)        34944     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 27, 27, 96)        0         \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 27, 27, 96)        384       \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 23, 23, 256)       614656    \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 11, 11, 256)       0         \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 11, 11, 256)       1024      \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 9, 9, 384)         885120    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 9, 9, 384)         1536      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 7, 7, 384)         1327488   \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 7, 7, 384)         1536      \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 5, 5, 256)         884992    \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 2, 2, 256)         0         \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 2, 2, 256)         1024      \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 4096)              4198400   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 4096)              16384     \n_________________________________________________________________\ndense_5 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 4096)              16384     \n_________________________________________________________________\ndense_6 (Dense)              (None, 1000)              4097000   \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 1000)              0         \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 1000)              4000      \n_________________________________________________________________\ndense_7 (Dense)              (None, 3)                 3003      \n=================================================================\nTotal params: 28,869,187\nTrainable params: 28,848,051\nNon-trainable params: 21,136\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=SGD(learning_rate=0.001, momentum=0.9, decay = 0.005), \n             loss = \"sparse_categorical_crossentropy\",\n             metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:43.902886Z","iopub.execute_input":"2022-12-13T08:46:43.903502Z","iopub.status.idle":"2022-12-13T08:46:43.916457Z","shell.execute_reply.started":"2022-12-13T08:46:43.903462Z","shell.execute_reply":"2022-12-13T08:46:43.915191Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"datasets_directory = \"../input/dogs-and-cats-image-classification/dataset/\"","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:45.576821Z","iopub.execute_input":"2022-12-13T08:46:45.577434Z","iopub.status.idle":"2022-12-13T08:46:45.583354Z","shell.execute_reply.started":"2022-12-13T08:46:45.577377Z","shell.execute_reply":"2022-12-13T08:46:45.581826Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:46.040653Z","iopub.execute_input":"2022-12-13T08:46:46.041062Z","iopub.status.idle":"2022-12-13T08:46:46.047074Z","shell.execute_reply.started":"2022-12-13T08:46:46.041030Z","shell.execute_reply":"2022-12-13T08:46:46.045347Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_dataGenerator = ImageDataGenerator(rescale = 1./255,\n                                         \n                                         shear_range = 0.2, \n                                         zoom_range=0.2,\n                                         width_shift_range=0.2,\n                                         height_shift_range=0.2, \n                                         fill_mode=\"nearest\"\n                                        )\n\nvalidation_dataGenerator = ImageDataGenerator(rescale = 1./255)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:46.296390Z","iopub.execute_input":"2022-12-13T08:46:46.297372Z","iopub.status.idle":"2022-12-13T08:46:46.305082Z","shell.execute_reply.started":"2022-12-13T08:46:46.297315Z","shell.execute_reply":"2022-12-13T08:46:46.303858Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Load the datasets from the folder\ntrainDatasets = train_dataGenerator.flow_from_directory(datasets_directory+\"/training_set\", \n                                                       target_size=(224, 224),\n                                                       batch_size=batch_size, \n                                                       class_mode='binary')\n\nvalidationDatasets = validation_dataGenerator.flow_from_directory(datasets_directory+\"/test_set\", \n                                                       target_size=(224, 224),\n                                                       batch_size=batch_size, \n                                                       class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:46.566937Z","iopub.execute_input":"2022-12-13T08:46:46.567717Z","iopub.status.idle":"2022-12-13T08:46:48.128698Z","shell.execute_reply.started":"2022-12-13T08:46:46.567670Z","shell.execute_reply":"2022-12-13T08:46:48.127375Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Found 8000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"classInformation = trainDatasets.class_indices\nprint(\"Class Information: {}\".format(classInformation))\nclasses = list(classInformation)\nprint(\"Class Names: {}\".format(classes))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:48.130603Z","iopub.execute_input":"2022-12-13T08:46:48.131433Z","iopub.status.idle":"2022-12-13T08:46:48.137783Z","shell.execute_reply.started":"2022-12-13T08:46:48.131392Z","shell.execute_reply":"2022-12-13T08:46:48.136457Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Class Information: {'cats': 0, 'dogs': 1}\nClass Names: ['cats', 'dogs']\n","output_type":"stream"}]},{"cell_type":"code","source":"classSamplesT = trainDatasets.samples\nprint(\"Training Data Samples: {}\".format(classSamplesT))\nclassSamplesV = validationDatasets.samples\nprint(\"Validation Data Samples: {}\".format(classSamplesV))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:48.139679Z","iopub.execute_input":"2022-12-13T08:46:48.140058Z","iopub.status.idle":"2022-12-13T08:46:48.153896Z","shell.execute_reply.started":"2022-12-13T08:46:48.140024Z","shell.execute_reply":"2022-12-13T08:46:48.152551Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Training Data Samples: 8000\nValidation Data Samples: 2000\n","output_type":"stream"}]},{"cell_type":"code","source":"weghtPath = \"best_weights_9.hdf5\"\ncheckPoint = ModelCheckpoint(weghtPath, monitor=\"val_acc\", verbose = 1, save_best_only = True, save_weghts_only = True, mode = \"max\")\ncallBacksList = [checkPoint]","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:48.443734Z","iopub.execute_input":"2022-12-13T08:46:48.444168Z","iopub.status.idle":"2022-12-13T08:46:48.449780Z","shell.execute_reply.started":"2022-12-13T08:46:48.444134Z","shell.execute_reply":"2022-12-13T08:46:48.448940Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"history = model.fit(trainDatasets,\n                    steps_per_epoch = classSamplesT//batch_size, \n                    validation_data=validationDatasets,\n                    epochs=20, \n                    validation_steps=classSamplesV//batch_size, \n                    callbacks=callBacksList)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:46:49.339932Z","iopub.execute_input":"2022-12-13T08:46:49.340346Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n62/62 [==============================] - 392s 6s/step - loss: 1.4086 - accuracy: 0.4098 - val_loss: 0.9753 - val_accuracy: 0.5427\nEpoch 2/20\n62/62 [==============================] - 371s 6s/step - loss: 1.1464 - accuracy: 0.4997 - val_loss: 0.9317 - val_accuracy: 0.5583\nEpoch 3/20\n62/62 [==============================] - 371s 6s/step - loss: 1.0450 - accuracy: 0.5250 - val_loss: 0.8832 - val_accuracy: 0.5599\nEpoch 4/20\n62/62 [==============================] - 370s 6s/step - loss: 0.9691 - accuracy: 0.5494 - val_loss: 0.8100 - val_accuracy: 0.5995\nEpoch 5/20\n62/62 [==============================] - 369s 6s/step - loss: 0.9220 - accuracy: 0.5659 - val_loss: 0.7577 - val_accuracy: 0.6281\nEpoch 6/20\n62/62 [==============================] - 371s 6s/step - loss: 0.8854 - accuracy: 0.5799 - val_loss: 0.7533 - val_accuracy: 0.6359\nEpoch 7/20\n62/62 [==============================] - 370s 6s/step - loss: 0.8483 - accuracy: 0.5976 - val_loss: 0.7138 - val_accuracy: 0.6594\nEpoch 8/20\n62/62 [==============================] - 369s 6s/step - loss: 0.8327 - accuracy: 0.6032 - val_loss: 0.6922 - val_accuracy: 0.6641\nEpoch 9/20\n62/62 [==============================] - 372s 6s/step - loss: 0.8088 - accuracy: 0.6085 - val_loss: 0.6827 - val_accuracy: 0.6615\nEpoch 10/20\n62/62 [==============================] - 376s 6s/step - loss: 0.7955 - accuracy: 0.6142 - val_loss: 0.6887 - val_accuracy: 0.6693\nEpoch 11/20\n62/62 [==============================] - 378s 6s/step - loss: 0.7779 - accuracy: 0.6255 - val_loss: 0.7096 - val_accuracy: 0.6583\nEpoch 12/20\n 7/62 [==>...........................] - ETA: 5:13 - loss: 0.7678 - accuracy: 0.6272","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}